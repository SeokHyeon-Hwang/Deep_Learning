{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "190313_DL_with_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kkOfW7BZr24G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "W-A3Yxj4gP9F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EDxoWWfvgc4n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "metadata": {
        "id": "qbKtnntHgjMP",
        "colab_type": "code",
        "outputId": "89e349f3-d05c-417c-fe45-15ccc8f81de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-urG6dqngmU3",
        "colab_type": "code",
        "outputId": "442ad9f9-7ed3-46fd-b681-d9ef3148ae69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "((X_train, y_train), (X_test, y_test)) = mnist.load_data()\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A4ZCvF7eg1eq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Processing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MoA8IpREg5YN",
        "colab_type": "code",
        "outputId": "312d59e9-3ce3-40fd-d07a-fa4677431c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(60000, 28*28)\n",
        "X_test = X_test.reshape(10000, 28*28)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784) (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f7KjPHfqia1U",
        "colab_type": "code",
        "outputId": "236234ba-88a3-44bb-fc13-5ce7b1cad374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_hot = to_categorical(y_train)\n",
        "y_test_hot = to_categorical(y_test)\n",
        "\n",
        "print(y_train_hot.shape, y_test_hot.shape)\n",
        "print('Label = {0}'.format(y_train[0:3]))\n",
        "y_train_hot[0:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10) (10000, 10)\n",
            "Label = [5 0 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "WJXeYHw6iz9m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ]
    },
    {
      "metadata": {
        "id": "zf87Ia4Ui6hx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multi-layer Neutral Network"
      ]
    },
    {
      "metadata": {
        "id": "OD-5Aa1pxjqn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multi_model_1\n",
        "\n",
        "*w1=+-1, size=(784, 1000)<br>\n",
        "*w2=+-1, size=(1000, 10)<br>\n",
        "*lr=0.00001<br>\n",
        "*epochs=100<br>"
      ]
    },
    {
      "metadata": {
        "id": "roenJ7LZjCQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.initializers import RandomUniform\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vPeJ4cl6jQiw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=1000,\n",
        "               kernel_initializer=RandomUniform(minval=-1, maxval=1),\n",
        "               activation='sigmoid',\n",
        "               input_dim=28*28))\n",
        "\n",
        "model.add(Dense(units=10,\n",
        "               kernel_initializer=RandomUniform(minval=-1, maxval=1),\n",
        "               activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TuJkd0ysjmsp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loss=Cross Entropy\n",
        "# optimizer=Stochastic Gradient Descent(SGD)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=SGD(lr=0.00001),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ypuucX_6pAM2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "def nowtime(past):\n",
        "  now = time.time()\n",
        "  print(now)\n",
        "  print('period[second] : {}'.format(now-past))\n",
        "  return now\n",
        "\n",
        "pasttime=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GyGQr5QFj8wH",
        "colab_type": "code",
        "outputId": "1009a9e3-a78f-4a9d-c440-74258c8ff589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3671
        }
      },
      "cell_type": "code",
      "source": [
        "pasttime=time.time()\n",
        "model.fit(X_train, y_train_hot, epochs=1000)\n",
        "print(nowtime(pasttime))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 17s 283us/step - loss: 9.3458 - acc: 0.0871\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 9.1995 - acc: 0.0868\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 9.0605 - acc: 0.0861\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 8.9293 - acc: 0.0859\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 8.8046 - acc: 0.0853\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 17s 287us/step - loss: 8.6856 - acc: 0.0849\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 18s 296us/step - loss: 8.5727 - acc: 0.0850\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 17s 287us/step - loss: 8.4655 - acc: 0.0850\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 17s 290us/step - loss: 8.3638 - acc: 0.0845\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 17s 287us/step - loss: 8.2668 - acc: 0.0849\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 17s 285us/step - loss: 8.1741 - acc: 0.0849\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 17s 291us/step - loss: 8.0862 - acc: 0.0852\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 17s 282us/step - loss: 8.0018 - acc: 0.0854\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 7.9208 - acc: 0.0854\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 7.8429 - acc: 0.0857\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 7.7677 - acc: 0.0861\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 7.6950 - acc: 0.0867\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 7.6250 - acc: 0.0868\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 7.5577 - acc: 0.0873\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 7.4922 - acc: 0.0884\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 7.4282 - acc: 0.0887\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 7.3650 - acc: 0.0891\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 7.3031 - acc: 0.0895\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 7.2424 - acc: 0.0900\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 17s 283us/step - loss: 7.1823 - acc: 0.0904\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 7.1228 - acc: 0.0908\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 7.0641 - acc: 0.0912\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 7.0054 - acc: 0.0918\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 17s 275us/step - loss: 6.9463 - acc: 0.0920\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 17s 287us/step - loss: 6.8874 - acc: 0.0928\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 6.8285 - acc: 0.0932\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 17s 285us/step - loss: 6.7695 - acc: 0.0938\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 6.7102 - acc: 0.0940\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 6.6511 - acc: 0.0941\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 17s 284us/step - loss: 6.5919 - acc: 0.0946\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 6.5334 - acc: 0.0948\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 6.4759 - acc: 0.0951\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 6.4188 - acc: 0.0954\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 6.3622 - acc: 0.0958\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 6.3063 - acc: 0.0964\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 6.2511 - acc: 0.0968\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 6.1968 - acc: 0.0969\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 6.1437 - acc: 0.0977\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 6.0919 - acc: 0.0979\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 6.0415 - acc: 0.0985\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 5.9926 - acc: 0.0990\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 5.9451 - acc: 0.0992\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 5.8990 - acc: 0.1000\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 17s 287us/step - loss: 5.8544 - acc: 0.0998\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 5.8108 - acc: 0.1003\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 5.7683 - acc: 0.1006\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 5.7273 - acc: 0.1013\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 5.6877 - acc: 0.1014\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 5.6492 - acc: 0.1017\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 5.6121 - acc: 0.1025\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 5.5766 - acc: 0.1027\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 5.5424 - acc: 0.1037\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 5.5096 - acc: 0.1036\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 5.4781 - acc: 0.1047\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 5.4480 - acc: 0.1045\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 5.4192 - acc: 0.1057\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 5.3913 - acc: 0.1055\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 5.3644 - acc: 0.1060\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 5.3385 - acc: 0.1058\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 5.3135 - acc: 0.1064\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 5.2895 - acc: 0.1065\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 5.2664 - acc: 0.1066\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 16s 266us/step - loss: 5.2442 - acc: 0.1070\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 5.2229 - acc: 0.1073\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 15s 256us/step - loss: 5.2023 - acc: 0.1074\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 5.1824 - acc: 0.1077\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 5.1630 - acc: 0.1078\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 5.1442 - acc: 0.1086\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 5.1257 - acc: 0.1086\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 5.1078 - acc: 0.1084\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 5.0906 - acc: 0.1092\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 5.0738 - acc: 0.1093\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 5.0573 - acc: 0.1096\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 5.0412 - acc: 0.1098\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 5.0256 - acc: 0.1102\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 5.0102 - acc: 0.1107\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 4.9949 - acc: 0.1109\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 4.9798 - acc: 0.1112\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 4.9650 - acc: 0.1119\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 4.9504 - acc: 0.1118\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 4.9359 - acc: 0.1116\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 4.9216 - acc: 0.1121\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 17s 283us/step - loss: 4.9073 - acc: 0.1124\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 15s 256us/step - loss: 4.8929 - acc: 0.1125\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 4.8784 - acc: 0.1124\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 4.8638 - acc: 0.1127\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 4.8491 - acc: 0.1131\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 4.8342 - acc: 0.1134\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 4.8191 - acc: 0.1140\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 4.8039 - acc: 0.1138\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 4.7885 - acc: 0.1135\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 4.7726 - acc: 0.1135\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 4.7563 - acc: 0.1140\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 4.7396 - acc: 0.1138\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 4.7225 - acc: 0.1142\n",
            "1552441910.3863578\n",
            "period[second] : 1634.7203695774078\n",
            "1552441910.3863578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2UM8G9hwkDKN",
        "colab_type": "code",
        "outputId": "bb2f3a24-eb31-4ed1-c054-3505f0006b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "y_predict = model.predict(X_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)\n",
        "\n",
        "accuracy = (y_predict == y_test).mean()\n",
        "\n",
        "print('Accuracy = {0:.5f}'.format(accuracy))\n",
        "pd.DataFrame({'y(actual)':y_test, 'y(predict)':y_predict}).head(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.11350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y(actual)</th>\n",
              "      <th>y(predict)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    y(actual)  y(predict)\n",
              "0           7           3\n",
              "1           2           1\n",
              "2           1           3\n",
              "3           0           3\n",
              "4           4           8\n",
              "5           1           3\n",
              "6           4           5\n",
              "7           9           2\n",
              "8           5           1\n",
              "9           9           3\n",
              "10          0           0\n",
              "11          6           0\n",
              "12          9           3\n",
              "13          0           0\n",
              "14          1           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "sAa1cfKLn2Wa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Single-layer Neural Network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CwNOn0KXsRTR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.initializers import RandomUniform\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8AVwQ25muc4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_s =Sequential()\n",
        "model_s.add(Dense(units=10,\n",
        "                 kernel_initializer=RandomUniform(minval=-1, maxval=1),\n",
        "                 activation='sigmoid',\n",
        "                 input_dim=28*28))\n",
        "\n",
        "# loss = Cross Entropy\n",
        "# optimizer = Stochastic Gradient Descent(SGD)\n",
        "model_s.compile(loss='categorical crossentropy',\n",
        "               optimizer=SGD(;r=0.00001),\n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gugfLXxrvFS2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train_hot, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JbHcvI2xvLdh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "y_predict = model_s.predict(X_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)\n",
        "\n",
        "accuracy = (y_predict == y_test).mean()\n",
        "\n",
        "print('Accuracy = {0:.5f}'.format(accuracy))\n",
        "pd.DataFrame({'y(actual)':y_test, 'y(predict)':y_predict}).head(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MU23iA71yByO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### => Multi_model1 결과\n",
        "\n",
        "*w1=+-1, size=(784, 1000)<br>\n",
        "*w2=+-1, size=(1000, 10)<br>\n",
        "*lr=0.00001<br>\n",
        "*epochs=100<br>\n",
        "\n",
        "*time = 27m<br>\n",
        "\n",
        "*Accuracy = 0.11350<br>"
      ]
    },
    {
      "metadata": {
        "id": "BGnl1uJZyb-P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multi_model2\n",
        "\n",
        "*w1=+-1, size=(784, 1000)<br>\n",
        "*w2=+-1, size=(1000, 10)<br>\n",
        "*lr=0.00001<br>\n",
        "*epochs=300<br>"
      ]
    },
    {
      "metadata": {
        "id": "mKmc0wEzyn-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=1000,\n",
        "               kernel_initializer=RandomUniform(minval=-1, maxval=+1),\n",
        "               activation='sigmoid',\n",
        "               input_dim=28*28))\n",
        "model.add(Dense(units=10,\n",
        "               kernel_initializer=RandomUniform(minval=-1, maxval=+1),\n",
        "               activation='sigmoid'))\n",
        "\n",
        "# loss=Cross Entropy\n",
        "# optimizer=Stochastic Gradient Descent(SGD)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.0001), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xff_cnQUz8_I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "def nowtime(past):\n",
        "  now = time.time()\n",
        "  print(now)\n",
        "  print('period[second] : {}'.format(now-past))\n",
        "  return now\n",
        "\n",
        "pasttime=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tM69bXCc0CC7",
        "colab_type": "code",
        "outputId": "b579ea36-84c0-4d9a-cd38-a975c2916ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10871
        }
      },
      "cell_type": "code",
      "source": [
        "pasttime=time.time()\n",
        "model.fit(X_train, y_train_hot, epochs=300)\n",
        "print(nowtime(pasttime))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 4.7205 - acc: 0.0966\n",
            "Epoch 2/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 3.5717 - acc: 0.0994\n",
            "Epoch 3/300\n",
            "60000/60000 [==============================] - 16s 258us/step - loss: 3.0127 - acc: 0.1038\n",
            "Epoch 4/300\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 2.7434 - acc: 0.1093\n",
            "Epoch 5/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.5943 - acc: 0.1155\n",
            "Epoch 6/300\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 2.5042 - acc: 0.1211\n",
            "Epoch 7/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.4450 - acc: 0.1270\n",
            "Epoch 8/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.4039 - acc: 0.1320\n",
            "Epoch 9/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.3743 - acc: 0.1358\n",
            "Epoch 10/300\n",
            "60000/60000 [==============================] - 16s 266us/step - loss: 2.3521 - acc: 0.1397\n",
            "Epoch 11/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.3347 - acc: 0.1429\n",
            "Epoch 12/300\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 2.3205 - acc: 0.1459\n",
            "Epoch 13/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.3088 - acc: 0.1483\n",
            "Epoch 14/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.2990 - acc: 0.1515\n",
            "Epoch 15/300\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 2.2908 - acc: 0.1534\n",
            "Epoch 16/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.2838 - acc: 0.1554\n",
            "Epoch 17/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.2776 - acc: 0.1568\n",
            "Epoch 18/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.2722 - acc: 0.1585\n",
            "Epoch 19/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.2674 - acc: 0.1598\n",
            "Epoch 20/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.2631 - acc: 0.1608\n",
            "Epoch 21/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.2593 - acc: 0.1618\n",
            "Epoch 22/300\n",
            "60000/60000 [==============================] - 15s 256us/step - loss: 2.2558 - acc: 0.1635\n",
            "Epoch 23/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.2526 - acc: 0.1646\n",
            "Epoch 24/300\n",
            "60000/60000 [==============================] - 16s 266us/step - loss: 2.2496 - acc: 0.1654\n",
            "Epoch 25/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 2.2468 - acc: 0.1666\n",
            "Epoch 26/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.2443 - acc: 0.1679\n",
            "Epoch 27/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.2420 - acc: 0.1685\n",
            "Epoch 28/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.2398 - acc: 0.1687\n",
            "Epoch 29/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.2375 - acc: 0.1691\n",
            "Epoch 30/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.2355 - acc: 0.1702\n",
            "Epoch 31/300\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 2.2335 - acc: 0.1701\n",
            "Epoch 32/300\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 2.2317 - acc: 0.1708\n",
            "Epoch 33/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.2299 - acc: 0.1714\n",
            "Epoch 34/300\n",
            "60000/60000 [==============================] - 16s 266us/step - loss: 2.2282 - acc: 0.1719\n",
            "Epoch 35/300\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 2.2266 - acc: 0.1716\n",
            "Epoch 36/300\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 2.2250 - acc: 0.1723\n",
            "Epoch 37/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.2235 - acc: 0.1719\n",
            "Epoch 38/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.2220 - acc: 0.1730\n",
            "Epoch 39/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 2.2205 - acc: 0.1735\n",
            "Epoch 40/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 2.2191 - acc: 0.1735\n",
            "Epoch 41/300\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 2.2177 - acc: 0.1732\n",
            "Epoch 42/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.2163 - acc: 0.1740\n",
            "Epoch 43/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 2.2150 - acc: 0.1739\n",
            "Epoch 44/300\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 2.2136 - acc: 0.1746\n",
            "Epoch 45/300\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 2.2123 - acc: 0.1751\n",
            "Epoch 46/300\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 2.2110 - acc: 0.1757\n",
            "Epoch 47/300\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 2.2097 - acc: 0.1752\n",
            "Epoch 48/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 2.2085 - acc: 0.1759\n",
            "Epoch 49/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 2.2072 - acc: 0.1760\n",
            "Epoch 50/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.2060 - acc: 0.1761\n",
            "Epoch 51/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.2048 - acc: 0.1759\n",
            "Epoch 52/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.2035 - acc: 0.1762\n",
            "Epoch 53/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.2024 - acc: 0.1761\n",
            "Epoch 54/300\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 2.2012 - acc: 0.1762\n",
            "Epoch 55/300\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 2.2001 - acc: 0.1768\n",
            "Epoch 56/300\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 2.1990 - acc: 0.1769\n",
            "Epoch 57/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.1979 - acc: 0.1772\n",
            "Epoch 58/300\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 2.1967 - acc: 0.1773\n",
            "Epoch 59/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.1956 - acc: 0.1778\n",
            "Epoch 60/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.1945 - acc: 0.1776\n",
            "Epoch 61/300\n",
            "60000/60000 [==============================] - 16s 266us/step - loss: 2.1935 - acc: 0.1773\n",
            "Epoch 62/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.1924 - acc: 0.1778\n",
            "Epoch 63/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 2.1913 - acc: 0.1777\n",
            "Epoch 64/300\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 2.1903 - acc: 0.1772\n",
            "Epoch 65/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.1892 - acc: 0.1782\n",
            "Epoch 66/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.1882 - acc: 0.1778\n",
            "Epoch 67/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.1872 - acc: 0.1777\n",
            "Epoch 68/300\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 2.1862 - acc: 0.1782\n",
            "Epoch 69/300\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 2.1852 - acc: 0.1782\n",
            "Epoch 70/300\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 2.1842 - acc: 0.1776\n",
            "Epoch 71/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.1832 - acc: 0.1782\n",
            "Epoch 72/300\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 2.1822 - acc: 0.1778\n",
            "Epoch 73/300\n",
            "60000/60000 [==============================] - 17s 290us/step - loss: 2.1813 - acc: 0.1783\n",
            "Epoch 74/300\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 2.1803 - acc: 0.1777\n",
            "Epoch 75/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.1793 - acc: 0.1776\n",
            "Epoch 76/300\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 2.1783 - acc: 0.1786\n",
            "Epoch 77/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.1774 - acc: 0.1791\n",
            "Epoch 78/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 2.1764 - acc: 0.1785\n",
            "Epoch 79/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.1754 - acc: 0.1792\n",
            "Epoch 80/300\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 2.1744 - acc: 0.1784\n",
            "Epoch 81/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 2.1735 - acc: 0.1782\n",
            "Epoch 82/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 2.1725 - acc: 0.1787\n",
            "Epoch 83/300\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 2.1716 - acc: 0.1791\n",
            "Epoch 84/300\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 2.1706 - acc: 0.1787\n",
            "Epoch 85/300\n",
            "60000/60000 [==============================] - 16s 258us/step - loss: 2.1697 - acc: 0.1788\n",
            "Epoch 86/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.1687 - acc: 0.1791\n",
            "Epoch 87/300\n",
            "60000/60000 [==============================] - 15s 248us/step - loss: 2.1678 - acc: 0.1796\n",
            "Epoch 88/300\n",
            "60000/60000 [==============================] - 15s 249us/step - loss: 2.1668 - acc: 0.1788\n",
            "Epoch 89/300\n",
            "60000/60000 [==============================] - 15s 248us/step - loss: 2.1658 - acc: 0.1788\n",
            "Epoch 90/300\n",
            "60000/60000 [==============================] - 15s 247us/step - loss: 2.1649 - acc: 0.1795\n",
            "Epoch 91/300\n",
            "60000/60000 [==============================] - 15s 250us/step - loss: 2.1639 - acc: 0.1786\n",
            "Epoch 92/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.1629 - acc: 0.1790\n",
            "Epoch 93/300\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 2.1620 - acc: 0.1790\n",
            "Epoch 94/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.1610 - acc: 0.1789\n",
            "Epoch 95/300\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 2.1601 - acc: 0.1789\n",
            "Epoch 96/300\n",
            "60000/60000 [==============================] - 16s 258us/step - loss: 2.1592 - acc: 0.1790\n",
            "Epoch 97/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.1582 - acc: 0.1789\n",
            "Epoch 98/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.1573 - acc: 0.1788\n",
            "Epoch 99/300\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 2.1564 - acc: 0.1789\n",
            "Epoch 100/300\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 2.1554 - acc: 0.1793\n",
            "Epoch 101/300\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 2.1544 - acc: 0.1798\n",
            "Epoch 102/300\n",
            "60000/60000 [==============================] - 15s 256us/step - loss: 2.1535 - acc: 0.1791\n",
            "Epoch 103/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.1526 - acc: 0.1787\n",
            "Epoch 104/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.1516 - acc: 0.1792\n",
            "Epoch 105/300\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 2.1506 - acc: 0.1791\n",
            "Epoch 106/300\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 2.1497 - acc: 0.1784\n",
            "Epoch 107/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.1487 - acc: 0.1787\n",
            "Epoch 108/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.1478 - acc: 0.1792\n",
            "Epoch 109/300\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 2.1468 - acc: 0.1788\n",
            "Epoch 110/300\n",
            "60000/60000 [==============================] - 16s 258us/step - loss: 2.1458 - acc: 0.1794\n",
            "Epoch 111/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.1448 - acc: 0.1791\n",
            "Epoch 112/300\n",
            "60000/60000 [==============================] - 16s 266us/step - loss: 2.1439 - acc: 0.1791\n",
            "Epoch 113/300\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 2.1429 - acc: 0.1782\n",
            "Epoch 114/300\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 2.1420 - acc: 0.1787\n",
            "Epoch 115/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.1410 - acc: 0.1790\n",
            "Epoch 116/300\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 2.1400 - acc: 0.1781\n",
            "Epoch 117/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.1391 - acc: 0.1785\n",
            "Epoch 118/300\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 2.1381 - acc: 0.1785\n",
            "Epoch 119/300\n",
            "60000/60000 [==============================] - 15s 250us/step - loss: 2.1372 - acc: 0.1788\n",
            "Epoch 120/300\n",
            "60000/60000 [==============================] - 15s 246us/step - loss: 2.1362 - acc: 0.1789\n",
            "Epoch 121/300\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 2.1352 - acc: 0.1787\n",
            "Epoch 122/300\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 2.1343 - acc: 0.1784\n",
            "Epoch 123/300\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 2.1333 - acc: 0.1775\n",
            "Epoch 124/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.1323 - acc: 0.1775\n",
            "Epoch 125/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.1314 - acc: 0.1779\n",
            "Epoch 126/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.1304 - acc: 0.1777\n",
            "Epoch 127/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.1294 - acc: 0.1784\n",
            "Epoch 128/300\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 2.1284 - acc: 0.1780\n",
            "Epoch 129/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.1275 - acc: 0.1780\n",
            "Epoch 130/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.1265 - acc: 0.1781\n",
            "Epoch 131/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.1255 - acc: 0.1779\n",
            "Epoch 132/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.1245 - acc: 0.1780\n",
            "Epoch 133/300\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 2.1235 - acc: 0.1782\n",
            "Epoch 134/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.1225 - acc: 0.1775\n",
            "Epoch 135/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 2.1215 - acc: 0.1779\n",
            "Epoch 136/300\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 2.1205 - acc: 0.1777\n",
            "Epoch 137/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.1194 - acc: 0.1774\n",
            "Epoch 138/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.1184 - acc: 0.1773\n",
            "Epoch 139/300\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 2.1174 - acc: 0.1780\n",
            "Epoch 140/300\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 2.1164 - acc: 0.1770\n",
            "Epoch 141/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.1154 - acc: 0.1773\n",
            "Epoch 142/300\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 2.1144 - acc: 0.1776\n",
            "Epoch 143/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.1134 - acc: 0.1776\n",
            "Epoch 144/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.1123 - acc: 0.1768\n",
            "Epoch 145/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.1113 - acc: 0.1769\n",
            "Epoch 146/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.1103 - acc: 0.1767\n",
            "Epoch 147/300\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 2.1092 - acc: 0.1763\n",
            "Epoch 148/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.1082 - acc: 0.1769\n",
            "Epoch 149/300\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 2.1072 - acc: 0.1762\n",
            "Epoch 150/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.1061 - acc: 0.1762\n",
            "Epoch 151/300\n",
            "60000/60000 [==============================] - 15s 247us/step - loss: 2.1051 - acc: 0.1762\n",
            "Epoch 152/300\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 2.1040 - acc: 0.1764\n",
            "Epoch 153/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 2.1030 - acc: 0.1759\n",
            "Epoch 154/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.1020 - acc: 0.1761\n",
            "Epoch 155/300\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 2.1010 - acc: 0.1762\n",
            "Epoch 156/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 2.1000 - acc: 0.1769\n",
            "Epoch 157/300\n",
            "60000/60000 [==============================] - 16s 266us/step - loss: 2.0990 - acc: 0.1759\n",
            "Epoch 158/300\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 2.0979 - acc: 0.1753\n",
            "Epoch 159/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 2.0969 - acc: 0.1758\n",
            "Epoch 160/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.0959 - acc: 0.1763\n",
            "Epoch 161/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.0948 - acc: 0.1755\n",
            "Epoch 162/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.0938 - acc: 0.1756\n",
            "Epoch 163/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.0927 - acc: 0.1755\n",
            "Epoch 164/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.0916 - acc: 0.1757\n",
            "Epoch 165/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.0905 - acc: 0.1753\n",
            "Epoch 166/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.0895 - acc: 0.1756\n",
            "Epoch 167/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.0884 - acc: 0.1753\n",
            "Epoch 168/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0874 - acc: 0.1755\n",
            "Epoch 169/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0863 - acc: 0.1746\n",
            "Epoch 170/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.0853 - acc: 0.1750\n",
            "Epoch 171/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0842 - acc: 0.1742\n",
            "Epoch 172/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.0832 - acc: 0.1755\n",
            "Epoch 173/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 2.0821 - acc: 0.1740\n",
            "Epoch 174/300\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 2.0811 - acc: 0.1746\n",
            "Epoch 175/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.0800 - acc: 0.1745\n",
            "Epoch 176/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.0790 - acc: 0.1744\n",
            "Epoch 177/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.0779 - acc: 0.1751\n",
            "Epoch 178/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0769 - acc: 0.1743\n",
            "Epoch 179/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.0758 - acc: 0.1738\n",
            "Epoch 180/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.0748 - acc: 0.1741\n",
            "Epoch 181/300\n",
            "60000/60000 [==============================] - 16s 266us/step - loss: 2.0737 - acc: 0.1739\n",
            "Epoch 182/300\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 2.0726 - acc: 0.1740\n",
            "Epoch 183/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.0716 - acc: 0.1741\n",
            "Epoch 184/300\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 2.0705 - acc: 0.1746\n",
            "Epoch 185/300\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 2.0694 - acc: 0.1736\n",
            "Epoch 186/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.0683 - acc: 0.1741\n",
            "Epoch 187/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.0673 - acc: 0.1731\n",
            "Epoch 188/300\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 2.0662 - acc: 0.1734\n",
            "Epoch 189/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0651 - acc: 0.1740\n",
            "Epoch 190/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.0640 - acc: 0.1736\n",
            "Epoch 191/300\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 2.0629 - acc: 0.1732\n",
            "Epoch 192/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.0619 - acc: 0.1739\n",
            "Epoch 193/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.0608 - acc: 0.1737\n",
            "Epoch 194/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.0597 - acc: 0.1734\n",
            "Epoch 195/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.0586 - acc: 0.1735\n",
            "Epoch 196/300\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 2.0576 - acc: 0.1732\n",
            "Epoch 197/300\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 2.0565 - acc: 0.1737\n",
            "Epoch 198/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.0554 - acc: 0.1741\n",
            "Epoch 199/300\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 2.0543 - acc: 0.1733\n",
            "Epoch 200/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.0532 - acc: 0.1734\n",
            "Epoch 201/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.0521 - acc: 0.1724\n",
            "Epoch 202/300\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 2.0510 - acc: 0.1734\n",
            "Epoch 203/300\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 2.0499 - acc: 0.1730\n",
            "Epoch 204/300\n",
            "60000/60000 [==============================] - 16s 258us/step - loss: 2.0488 - acc: 0.1731\n",
            "Epoch 205/300\n",
            "60000/60000 [==============================] - 15s 256us/step - loss: 2.0477 - acc: 0.1724\n",
            "Epoch 206/300\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 2.0467 - acc: 0.1726\n",
            "Epoch 207/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.0456 - acc: 0.1731\n",
            "Epoch 208/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.0445 - acc: 0.1720\n",
            "Epoch 209/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.0434 - acc: 0.1731\n",
            "Epoch 210/300\n",
            "60000/60000 [==============================] - 15s 256us/step - loss: 2.0423 - acc: 0.1729\n",
            "Epoch 211/300\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 2.0412 - acc: 0.1728\n",
            "Epoch 212/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.0401 - acc: 0.1730\n",
            "Epoch 213/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.0389 - acc: 0.1725\n",
            "Epoch 214/300\n",
            "60000/60000 [==============================] - 15s 249us/step - loss: 2.0379 - acc: 0.1726\n",
            "Epoch 215/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.0368 - acc: 0.1729\n",
            "Epoch 216/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.0357 - acc: 0.1727\n",
            "Epoch 217/300\n",
            "60000/60000 [==============================] - 15s 250us/step - loss: 2.0345 - acc: 0.1737\n",
            "Epoch 218/300\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 2.0334 - acc: 0.1734\n",
            "Epoch 219/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.0323 - acc: 0.1732\n",
            "Epoch 220/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.0312 - acc: 0.1725\n",
            "Epoch 221/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0301 - acc: 0.1730\n",
            "Epoch 222/300\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 2.0290 - acc: 0.1724\n",
            "Epoch 223/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.0278 - acc: 0.1724\n",
            "Epoch 224/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.0267 - acc: 0.1721\n",
            "Epoch 225/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.0256 - acc: 0.1723\n",
            "Epoch 226/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 2.0244 - acc: 0.1727\n",
            "Epoch 227/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.0233 - acc: 0.1728\n",
            "Epoch 228/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0221 - acc: 0.1727\n",
            "Epoch 229/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.0210 - acc: 0.1728\n",
            "Epoch 230/300\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 2.0199 - acc: 0.1727\n",
            "Epoch 231/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0188 - acc: 0.1727\n",
            "Epoch 232/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 2.0177 - acc: 0.1732\n",
            "Epoch 233/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.0165 - acc: 0.1725\n",
            "Epoch 234/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 2.0154 - acc: 0.1718\n",
            "Epoch 235/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0143 - acc: 0.1726\n",
            "Epoch 236/300\n",
            "60000/60000 [==============================] - 15s 258us/step - loss: 2.0132 - acc: 0.1730\n",
            "Epoch 237/300\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 2.0120 - acc: 0.1726\n",
            "Epoch 238/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 2.0109 - acc: 0.1727\n",
            "Epoch 239/300\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 2.0098 - acc: 0.1729\n",
            "Epoch 240/300\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 2.0087 - acc: 0.1719\n",
            "Epoch 241/300\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 2.0076 - acc: 0.1720\n",
            "Epoch 242/300\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 2.0065 - acc: 0.1721\n",
            "Epoch 243/300\n",
            "60000/60000 [==============================] - 15s 246us/step - loss: 2.0053 - acc: 0.1720\n",
            "Epoch 244/300\n",
            "60000/60000 [==============================] - 15s 247us/step - loss: 2.0042 - acc: 0.1723\n",
            "Epoch 245/300\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 2.0031 - acc: 0.1720\n",
            "Epoch 246/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.0020 - acc: 0.1724\n",
            "Epoch 247/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 2.0009 - acc: 0.1725\n",
            "Epoch 248/300\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 1.9998 - acc: 0.1719\n",
            "Epoch 249/300\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 1.9987 - acc: 0.1723\n",
            "Epoch 250/300\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 1.9975 - acc: 0.1721\n",
            "Epoch 251/300\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 1.9964 - acc: 0.1728\n",
            "Epoch 252/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 1.9953 - acc: 0.1726\n",
            "Epoch 253/300\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 1.9942 - acc: 0.1721\n",
            "Epoch 254/300\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 1.9931 - acc: 0.1720\n",
            "Epoch 255/300\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 1.9919 - acc: 0.1722\n",
            "Epoch 256/300\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 1.9908 - acc: 0.1723\n",
            "Epoch 257/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 1.9897 - acc: 0.1723\n",
            "Epoch 258/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 1.9886 - acc: 0.1727\n",
            "Epoch 259/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 1.9874 - acc: 0.1724\n",
            "Epoch 260/300\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 1.9863 - acc: 0.1727\n",
            "Epoch 261/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 1.9852 - acc: 0.1726\n",
            "Epoch 262/300\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 1.9841 - acc: 0.1724\n",
            "Epoch 263/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 1.9830 - acc: 0.1727\n",
            "Epoch 264/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 1.9819 - acc: 0.1721\n",
            "Epoch 265/300\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 1.9808 - acc: 0.1731\n",
            "Epoch 266/300\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 1.9798 - acc: 0.1726\n",
            "Epoch 267/300\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 1.9787 - acc: 0.1726\n",
            "Epoch 268/300\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 1.9776 - acc: 0.1729\n",
            "Epoch 269/300\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 1.9765 - acc: 0.1734\n",
            "Epoch 270/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 1.9754 - acc: 0.1731\n",
            "Epoch 271/300\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 1.9744 - acc: 0.1729\n",
            "Epoch 272/300\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 1.9733 - acc: 0.1729\n",
            "Epoch 273/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 1.9722 - acc: 0.1731\n",
            "Epoch 274/300\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 1.9711 - acc: 0.1728\n",
            "Epoch 275/300\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 1.9701 - acc: 0.1731\n",
            "Epoch 276/300\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 1.9690 - acc: 0.1727\n",
            "Epoch 277/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 1.9679 - acc: 0.1730\n",
            "Epoch 278/300\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 1.9669 - acc: 0.1727\n",
            "Epoch 279/300\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 1.9659 - acc: 0.1732\n",
            "Epoch 280/300\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 1.9648 - acc: 0.1733\n",
            "Epoch 281/300\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 1.9638 - acc: 0.1729\n",
            "Epoch 282/300\n",
            "60000/60000 [==============================] - 16s 269us/step - loss: 1.9627 - acc: 0.1730\n",
            "Epoch 283/300\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 1.9617 - acc: 0.1730\n",
            "Epoch 284/300\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 1.9606 - acc: 0.1735\n",
            "Epoch 285/300\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 1.9596 - acc: 0.1739\n",
            "Epoch 286/300\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 1.9585 - acc: 0.1737\n",
            "Epoch 287/300\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 1.9575 - acc: 0.1732\n",
            "Epoch 288/300\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 1.9564 - acc: 0.1740\n",
            "Epoch 289/300\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 1.9554 - acc: 0.1739\n",
            "Epoch 290/300\n",
            "60000/60000 [==============================] - 17s 285us/step - loss: 1.9543 - acc: 0.1736\n",
            "Epoch 291/300\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 1.9533 - acc: 0.1737\n",
            "Epoch 292/300\n",
            "60000/60000 [==============================] - 17s 275us/step - loss: 1.9523 - acc: 0.1739\n",
            "Epoch 293/300\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 1.9512 - acc: 0.1741\n",
            "Epoch 294/300\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 1.9502 - acc: 0.1734\n",
            "Epoch 295/300\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 1.9492 - acc: 0.1736\n",
            "Epoch 296/300\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 1.9481 - acc: 0.1736\n",
            "Epoch 297/300\n",
            "60000/60000 [==============================] - 17s 284us/step - loss: 1.9471 - acc: 0.1740\n",
            "Epoch 298/300\n",
            "60000/60000 [==============================] - 17s 275us/step - loss: 1.9461 - acc: 0.1735\n",
            "Epoch 299/300\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 1.9451 - acc: 0.1738\n",
            "Epoch 300/300\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 1.9441 - acc: 0.1737\n",
            "1552447792.0760775\n",
            "period[second] : 4757.568633079529\n",
            "1552447792.0760775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NYIO13CD0NHJ",
        "colab_type": "code",
        "outputId": "554d74e0-f6d5-4873-8149-88539661b988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "y_predict = model.predict(X_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)\n",
        "\n",
        "accuracy = (y_predict == y_test).mean()\n",
        "\n",
        "print('Accuracy = {0:.5f}'.format(accuracy))\n",
        "pd.DataFrame({'y(actual)':y_test, 'y(predict)':y_predict}).head(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.16850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y(actual)</th>\n",
              "      <th>y(predict)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    y(actual)  y(predict)\n",
              "0           7           4\n",
              "1           2           5\n",
              "2           1           4\n",
              "3           0           0\n",
              "4           4           7\n",
              "5           1           1\n",
              "6           4           4\n",
              "7           9           4\n",
              "8           5           4\n",
              "9           9           4\n",
              "10          0           4\n",
              "11          6           4\n",
              "12          9           4\n",
              "13          0           4\n",
              "14          1           5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "cZksCwy9GjNy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### => Multi_model2 결과\n",
        "\n",
        "*w1=+-1, size=(784, 1000)<br>\n",
        "*w2=+-1, size=(1000, 10)<br>\n",
        "*lr=0.00001<br>\n",
        "*epochs=300<br>\n",
        "\n",
        "*time = 79m<br>\n",
        "\n",
        "*Accuracy = 0.11350<br>"
      ]
    },
    {
      "metadata": {
        "id": "zrlbKpE1HeUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}